{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDreamMusic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJdcLqedYid63vEe52pchH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smhall97/hallucinating_GANs/blob/main/DeepDreamMusic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CrvOGmJEgiPm"
      },
      "source": [
        "# @title Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "import tqdm\n",
        "import scipy.ndimage as nd\n",
        "import os\n",
        "import torchvision\n",
        "import torchaudio\n",
        "import IPython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vHF_DN1IiaIh"
      },
      "source": [
        "# @title Helper functions (mean, std)\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "normalize = torchvision.transforms.Normalize(mean, std)\n",
        "preprocess = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize])\n",
        "\n",
        "\n",
        "def deprocess(image_np):\n",
        "    print(\"Deproccess, incoming image: \", type(image_np), image_np.shape)\n",
        "    image_np = image_np.transpose(1, 2, 0)\n",
        "    image_np = image_np * std.reshape((1, 1, 3)) + mean.reshape((1, 1, 3))\n",
        "    image_np = np.clip(image_np, 0.0, 255.0)\n",
        "    return image_np\n",
        "\n",
        "def clip(image_tensor):\n",
        "    for c in range(3):\n",
        "        m, s = mean[c], std[c]\n",
        "        image_tensor[0, c] = torch.clamp(image_tensor[0, c], -m / s, (1 - m) / s)\n",
        "    return image_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FQEg4GMjEOH"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWLjyL7PhVQM"
      },
      "source": [
        "# TODO: get params from Pablo for the path name\n",
        "\n",
        "path_to_model = f'/content/{}_{}.pt Load from drive\n",
        "\n",
        "model_state_dict = torch.load(path_to_model)\n",
        "trained_model.load_state_dict(model_state_dict)\n",
        "\n",
        "# Freeze parameters (we are not doing any model training here!)\n",
        "for param in trained_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E5t8ZsVjcd2"
      },
      "source": [
        "# Get input image for dreaming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqqPcH5ljiAD"
      },
      "source": [
        "# TODO: images for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftHIKK-WjNE-"
      },
      "source": [
        "# Dreaming function (without octaves)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIXAa8mojCBv"
      },
      "source": [
        "# @title Dreaming function\n",
        "\n",
        "def dream(image, model, iterations, lr, unit=None):\n",
        "    \"\"\" Updates the image to maximize outputs for n iterations \"\"\"\n",
        "    \n",
        "    if unit is None:\n",
        "        print(f\"Dreaming ... {image.shape}\")\n",
        "    else:\n",
        "        print(f\"Dream of {unit} {inet_classes[unit]} ... {image.shape}\")\n",
        "\n",
        "    image = preprocess(image)\n",
        "\n",
        "    # Convert the numpy array image into a requires_grad=True Tensor that we will optimize\n",
        "    image = torch.tensor(image, requires_grad=True, dtype=torch.float, device=DEVICE)\n",
        "            \n",
        "    # Optimization loop\n",
        "    for i in range(iterations):\n",
        "        model.zero_grad()\n",
        "        out = model(image.unsqueeze(0))\n",
        "\n",
        "        if unit is None:\n",
        "            # Dreaming on a whole layer \n",
        "            gain = out.norm()\n",
        "        else:\n",
        "            # Dreaming on a specific output neuron...\n",
        "            gain = out[0][unit]\n",
        "            \n",
        "        if i % 50 == 0:\n",
        "            print(f\"{i}: activation {gain.shape}: {gain}\")\n",
        "                        \n",
        "        gain.backward()\n",
        "        \n",
        "        # Update image using gradients...\n",
        "        #print(i, image.grad)\n",
        "        # print(\"data: \", image.data)\n",
        "        #avg_grad = np.abs(image.grad.data.cpu().numpy()).mean()\n",
        "        with torch.no_grad():\n",
        "            absgrad = torch.abs(image.grad)\n",
        "            norm_lr = lr / absgrad.mean()\n",
        "            image += norm_lr * image.grad\n",
        "            image = clip(image)\n",
        "        \n",
        "        image.grad.zero_()\n",
        "\n",
        "    return deprocess(image.detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PrH-nifj0XH"
      },
      "source": [
        "### Dreaming hyperparameters and input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2f2Z6jWjr0m"
      },
      "source": [
        "# Load image to be dreamed:\n",
        "image = ''\n",
        "\n",
        "# Hyper parameters for deep dreaming\n",
        "dreaming_layer = -1 # output layer\n",
        "dreaming_unit = int(1) # depends on genre of interest\n",
        "learning_rate = 1e-02\n",
        "iterations = 20 # number of times the deep dream loop should be run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD1XGfQSkTiX"
      },
      "source": [
        "### Run the dreaming function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo3Q--F9khVP"
      },
      "source": [
        "dreamed_image = dream(image, trained_model, iterations, learning_rate, unit=dreaming_unit)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}