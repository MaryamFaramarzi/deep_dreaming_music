{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_finetuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQrJbOobN/jcNZfqpTped4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "339b52426e83479eabf16c4f007901f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18134ddf94484b82b626d40e2b234d59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a784c6d2570c40398bfd9a130fae079f",
              "IPY_MODEL_dbaa3480a6544c48bfd06324fc96c4e3"
            ]
          }
        },
        "18134ddf94484b82b626d40e2b234d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a784c6d2570c40398bfd9a130fae079f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b04ff9878264b46b3aec97300d73662",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e20eccded264f6e96076c03670721ba"
          }
        },
        "dbaa3480a6544c48bfd06324fc96c4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2c8e4be87b542aba1bd2f3c142e5ebd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [06:59&lt;00:00, 1.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_585c023ff1204a739268bf5211cfe71f"
          }
        },
        "4b04ff9878264b46b3aec97300d73662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e20eccded264f6e96076c03670721ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2c8e4be87b542aba1bd2f3c142e5ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "585c023ff1204a739268bf5211cfe71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smhall97/hallucinating_GANs/blob/main/CNN_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjMXv4SamPoh"
      },
      "source": [
        "# @title Imports\n",
        "\n",
        "import os\n",
        "import glob\n",
        "#import imageio\n",
        "#import random, shutil\n",
        "import torch\n",
        "#import gc\n",
        "#import csv\n",
        "#import multiprocessing\n",
        "#import requests\n",
        "import time\n",
        "import copy\n",
        "#import librosa\n",
        "#import librosa.display\n",
        "\n",
        "#import pandas as pd\n",
        "import numpy as np\n",
        "#import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "#import IPython.display as display\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0ZN16-ZmYEs"
      },
      "source": [
        "# @title Set Device\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "      print(\"WARNING: For this notebook to perform best, \"\n",
        "          \"if possible, in the menu under `Runtime` -> \"\n",
        "          \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "      print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSmuUVoPmfJR",
        "outputId": "0a67dc3d-afdb-4922-bb50-c93006c1c58a"
      },
      "source": [
        "# @title Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #it will ask you for a verification code\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQQ-rKRinz0Y"
      },
      "source": [
        "# @title Paths and script parameters\n",
        "\n",
        "dummy_mode = True\n",
        "\n",
        "path = '/content/drive/MyDrive/HallucinatingGANs/Code/data/'\n",
        "\n",
        "transform = 'mel'\n",
        "\n",
        "n_fft = 1024\n",
        "n_mels = 128\n",
        "hop_length = 256 # smaller hop size leads to better reconstruction but takes longer to compute\n",
        "power = 2.0 # squared power spectrogram\n",
        "samplerate =  22050\n",
        "\n",
        "def get_cfg_transform(t):\n",
        "  if t == 'stft':\n",
        "    params = '{}_{}'.format(str(n_fft), str(hop_length))\n",
        "  \n",
        "  elif t == 'mel':\n",
        "    params = '{}_{}_{}'.format(str(n_fft), str(hop_length), n_mels)\n",
        "\n",
        "  return params\n",
        "\n",
        "#if dummy_mode:\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laZtGJA-zYT1"
      },
      "source": [
        "# @title some functions\n",
        "\n",
        "def scale_minmax(X):\n",
        "\n",
        "    X_scaled = (X - X.min()) / (X.max() - X.min())\n",
        "\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def pickle_loader(file):\n",
        "  with open(file, 'rb') as f:\n",
        "      data = pickle.load(f)\n",
        "      data = np.transpose(data, axes=[1, 2, 0])\n",
        "      data = scale_minmax(data)\n",
        "\n",
        "      zeros = np.zeros(data.shape)\n",
        "\n",
        "      data = np.concatenate((data, zeros, zeros), axis=2)\n",
        "\n",
        "  return(data)\n",
        "\n",
        "\n",
        "def make_sets(classes, items_per_class, ratios):\n",
        "  \"\"\"\n",
        "  parameters:\n",
        "  classes: number of classes in dataset\n",
        "  items_per_class: elements per class (assumes that the dataset is balanced across classes)\n",
        "  ratios: list or array with ratios for each subset [ratio_trainining, ratio_validation, ratio_test]\n",
        "  \"\"\"\n",
        "\n",
        "  train_size = ratios[0] * items_per_class\n",
        "  val_size = ratios[1] * items_per_class\n",
        "  test_size = ratios[2] * items_per_class\n",
        "\n",
        "  test_ix, val_ix, train_ix = np.array([]),np.array([]),np.array([])\n",
        "\n",
        "  for i in range(classes): \n",
        "    class_ix = items_per_class * i\n",
        "    \n",
        "    train_ix = np.append(train_ix, np.arange(train_size) + class_ix)\n",
        "    val_ix = np.append(val_ix, np.arange(train_size, train_size + val_size) + class_ix)\n",
        "    test_ix = np.append(test_ix, np.arange(train_size + val_size, train_size + val_size + test_size) + class_ix)\n",
        "\n",
        "  return train_ix.astype(int), val_ix.astype(int), test_ix.astype(int)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP451jTZqW_u",
        "outputId": "09bc8afd-7291-4c5c-e8d8-dfe1dea5c879"
      },
      "source": [
        "params = get_cfg_transform(transform)\n",
        "\n",
        "data_dir = os.path.join(os.path.abspath(path), 'spectrograms', transform, params)\n",
        "print(data_dir)\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.CenterCrop((128, 2580)),\n",
        "                                      transforms.Normalize(mean=[.5,.5,.5], std=[.5,.5,.5])\n",
        "                                      ])\n",
        "\n",
        "dataset = torchvision.datasets.DatasetFolder(root=data_dir,\n",
        "                                             transform = data_transforms, \n",
        "                                             loader=pickle_loader, \n",
        "                                             extensions='.pkl', \n",
        "                                             )\n",
        "\n",
        "genres = list(os.listdir(data_dir))\n",
        "n_classes = len(genres) \n",
        "\n",
        "train_ix, val_ix, test_ix = make_sets(n_classes, 100, [.8, .1, .1])\n",
        "\n",
        "subsets = {\n",
        "          'train': torch.utils.data.Subset(dataset, train_ix),\n",
        "          'val': torch.utils.data.Subset(dataset, val_ix)\n",
        "          }\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(subsets[x], batch_size=25,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}\n",
        "print(dataset_sizes)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HallucinatingGANs/Code/data/spectrograms/mel/1024_256_128\n",
            "{'train': 800, 'val': 100}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTus8BSbVO6g",
        "outputId": "bbf9bc82-1d64-41ff-a8d0-efe3c0fe24a3"
      },
      "source": [
        "#dataset[0][0].shape\n",
        "print(dataset[0][0].shape, dataset[0][0].dtype)\n",
        "print(dataset)\n",
        "print(torch.min(dataset[0][0]))\n",
        "print(torch.max(dataset[0][0]))\n",
        "print(torch.mean(dataset[0][0]))\n",
        "print(torch.std(dataset[0][0]))\n",
        "#print(dataset[0][0][1])\n",
        "#print(dataset[0][0][2])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 128, 2580]) torch.float64\n",
            "Dataset DatasetFolder\n",
            "    Number of datapoints: 1000\n",
            "    Root location: /content/drive/MyDrive/HallucinatingGANs/Code/data/spectrograms/mel/1024_256_128\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               CenterCrop(size=(128, 2580))\n",
            "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "           )\n",
            "tensor(-1., dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n",
            "tensor(-0.9989, dtype=torch.float64)\n",
            "tensor(0.0109, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifrLGjQ8PO-L",
        "outputId": "b1b66322-9a87-44fa-ee09-f8758f849b9e"
      },
      "source": [
        "# @title Set device (GPU or CPU)\n",
        "# NMA code\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device\n",
        "\n",
        "device = set_device()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "339b52426e83479eabf16c4f007901f1",
            "18134ddf94484b82b626d40e2b234d59",
            "a784c6d2570c40398bfd9a130fae079f",
            "dbaa3480a6544c48bfd06324fc96c4e3",
            "4b04ff9878264b46b3aec97300d73662",
            "9e20eccded264f6e96076c03670721ba",
            "e2c8e4be87b542aba1bd2f3c142e5ebd",
            "585c023ff1204a739268bf5211cfe71f"
          ]
        },
        "id": "M4oQ--ymPWNF",
        "outputId": "1f295e8f-1802-428a-850a-f16bd915fe24"
      },
      "source": [
        "# @title Load pretrained VGG\n",
        "\"\"\"\n",
        "code extracted from:\n",
        "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor\n",
        "https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze the network except the last layer / unfreeze layers to allow finetuning\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = True # If True it will train\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "# Add on classifier\n",
        "\n",
        "vgg16.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(vgg16.classifier[3].in_features, 256),\n",
        "                      nn.ReLU(), \n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "339b52426e83479eabf16c4f007901f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZDEnGhh_Fy6",
        "outputId": "21537724-21f4-4ae5-ac00-afb7f7abb395"
      },
      "source": [
        "print(vgg16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Sequential(\n",
            "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "      (3): LogSoftmax(dim=1)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEQnRe9iSZ4w"
      },
      "source": [
        "# @title Train model function from PyTorch\n",
        "\n",
        "# Original code from this tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "    # train_loss, validation_loss = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            num_examples = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                num_examples += inputs.size(0)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs.float())\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            # Different to tutorial, hardcoded dataset size\n",
        "            # print(dataset_sizes) from above \n",
        "            \n",
        "            #if phase == 'train':\n",
        "            #    num_examples = len(train_loader) * len(next(iter(train_loader))[0]) \n",
        "            #else:\n",
        "            #    num_examples = len(val_loader) * len(next(iter(val_loader))[0])\n",
        "            print('number of examples in loader = ', num_examples)\n",
        "            print(f'RUNNING LOSS: {running_loss}, RUNNING CORRECTS: {running_corrects}')\n",
        "\n",
        "            epoch_loss = running_loss / num_examples\n",
        "            print()\n",
        "            epoch_acc = running_corrects.double() / num_examples\n",
        "            if phase == 'train':\n",
        "              train_acc_list.append(epoch_acc)\n",
        "            else:\n",
        "              val_acc_list.append(epoch_acc)\n",
        "          \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    # model = model.to('cuda')\n",
        "    return model, train_acc_list, val_acc_list"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTqgjfnPSi5U",
        "outputId": "d47d37eb-2036-41e9-d966-06df2e4d9b96"
      },
      "source": [
        "# model trains - change num_epochs to increase training time\n",
        "vgg16 = vgg16.float()\n",
        "model_ft, train_acc_list, val_acc_list = train_model(vgg16.to(device), criterion, optimizer_conv, exp_lr_scheduler,\n",
        "                       num_epochs=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}